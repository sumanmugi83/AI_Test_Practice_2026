# Chapter 4 Exercises - Automation Tester

- **Author:** Pramod Dutta
- **Role:** Principal SDET
- **Website:** [The Testing Academy](https://thetestingacademy.com/)
- **LinkedIn:** [linkedin.com/in/pramoddutta](https://www.linkedin.com/in/pramoddutta/)

---

> These exercises are designed for **Automation Testers** focusing on Playwright code generation, Claude Code workflows, and Augment framework integration — turning AI into runnable test automation.

---

## Prerequisites

- Completed [Chapter 1](../../chapter_01_foundation_model/ch_01_foundation_model.md) - Foundation
- Completed [Chapter 2](../../chapter_02_prompt_engineering/ch_02_prompt_engineering.md) - RICE POT
- Completed [Chapter 3](../../chapter_03_essential_ai_tools_setup/ch_03_essential_ai_tools_setup.md) - VS Code + Copilot/Augment set up
- Python + Playwright installed (`pip install playwright pytest pytest-playwright && playwright install`)

---

## Exercise 1: Playwright Test Generation with AI

**Difficulty:** Beginner
**Time:** 40 minutes
**Tool:** GitHub Copilot / Anti Gravity / Claude in VS Code

### Scenario

Generate a complete Playwright test suite for a **Login Page** using AI coding assistants.

```
Login Page Requirements:
- URL: /login
- Email input field (id: email)
- Password input field (id: password)
- Remember Me checkbox (id: remember-me)
- Submit button (class: login-btn)
- Error message display (class: error-msg)
- Forgot password link (id: forgot-pwd)
- Success: redirects to /dashboard
```

### Tasks

1. **Create project structure:**
```bash
mkdir -p login-test/tests/pages
cd login-test
```

2. **Generate Page Object** using AI (comment-driven with Copilot):
   - Write a comment describing LoginPage
   - Accept AI completion
   - Verify all locators match the spec

3. **Generate test file** covering:
   - TC-001: Valid login → dashboard redirect
   - TC-002: Invalid password → error message
   - TC-003: Empty email → validation error
   - TC-004: Empty password → validation error
   - TC-005: Remember Me checkbox functionality

4. **Generate conftest.py** with browser fixtures

5. **Review generated code:**
   - Are selectors correct per the spec?
   - Are assertions meaningful?
   - Are waits proper (no sleep)?

### Deliverables

- [ ] `tests/pages/login_page.py` (AI-generated Page Object)
- [ ] `tests/e2e/test_login.py` (5 test functions)
- [ ] `tests/conftest.py` (fixtures)
- [ ] Code review notes (what you changed from AI output)

---

## Exercise 2: Claude Code End-to-End Walkthrough

**Difficulty:** Intermediate
**Time:** 60 minutes
**Tool:** Claude Code (terminal)

### Scenario

Use Claude Code to build a complete test automation project from scratch for a **Shopping Cart Feature**.

```
Shopping Cart Feature:
- Add item to cart (button: .add-to-cart on product page)
- View cart (/cart page)
- Update quantity (input: .qty-input per item)
- Remove item (button: .remove-btn per item)
- Cart total updates dynamically
- "Cart is empty" message when no items
- Checkout button visible when cart has items
```

### Tasks

1. **Start Claude Code:**
```bash
mkdir cart-test && cd cart-test
claude
```

2. **Phase 1 - Setup:** Ask Claude Code to create the full project structure
3. **Phase 2 - Design:** Feed the requirements, get test scenarios
4. **Phase 3 - Generate:** Ask Claude Code to create:
   - ProductPage (Page Object)
   - CartPage (Page Object)
   - test_cart.py (full test file)
   - conftest.py with fixtures
5. **Phase 4 - Review:** Read all generated code, identify issues
6. **Phase 5 - Document:** Ask Claude Code to generate a test summary

### Deliverables

- [ ] Complete project created via Claude Code
- [ ] All Page Objects and test files
- [ ] Screenshots/logs of Claude Code conversation
- [ ] Code review notes
- [ ] Test summary report generated by Claude Code

---

## Exercise 3: Augment Framework Integration

**Difficulty:** Intermediate
**Time:** 45 minutes
**Tool:** Augment in VS Code

### Scenario

You have an **existing test project** with login tests. Use Augment to extend it with new tests that match the existing patterns.

### Setup

First create a base project with existing tests:

```python
# tests/pages/base_page.py
from playwright.async_api import Page

class BasePage:
    def __init__(self, page: Page):
        self.page = page

    async def navigate(self, path: str = "/"):
        await self.page.goto(f"https://staging.ecommerce.com{path}")
```

```python
# tests/pages/login_page.py
from playwright.async_api import Page, expect
from tests.pages.base_page import BasePage

class LoginPage(BasePage):
    def __init__(self, page: Page):
        super().__init__(page)
        self.email = page.locator('#email')
        self.password = page.locator('#password')
        self.submit = page.locator('button.submit-btn')
        self.error = page.locator('.error-message')

    async def login(self, email: str, password: str):
        await self.navigate("/login")
        await self.email.fill(email)
        await self.password.fill(password)
        await self.submit.click()
```

```python
# tests/e2e/test_login.py
import pytest
from playwright.async_api import Page, expect
from tests.pages.login_page import LoginPage

@pytest.mark.asyncio
async def test_login_success(page: Page):
    """Valid login redirects to dashboard."""
    login = LoginPage(page)
    await login.login("user@test.com", "Pass@123")
    await expect(page).to_have_url("**/dashboard")
```

### Tasks

1. **Open the project in VS Code** with Augment active
2. **Wait for Augment to index** all files
3. **Use Augment chat** to generate:
   - `tests/pages/signup_page.py` — matching LoginPage style
   - `tests/e2e/test_signup.py` — matching test_login.py style
4. **Verify style matching:**
   - Does it use `BasePage` inheritance?
   - Does it use same locator naming pattern?
   - Does it use same assertion style?
5. **Ask Augment to refactor** — find any inconsistencies across files

### Deliverables

- [ ] `signup_page.py` generated by Augment
- [ ] `test_signup.py` generated by Augment
- [ ] Style comparison: Show how Augment matched existing patterns
- [ ] Refactoring suggestions from Augment
- [ ] Notes on what Augment did well vs. what needed manual fixing

---

## Exercise 4: API Test Automation

**Difficulty:** Advanced
**Time:** 50 minutes
**Tool:** Claude Code / VS Code + AI

### Scenario

Generate a complete API test suite for a **User Management API** using AI.

```
API Endpoints:
GET    /api/users         - List users (paginated: ?page=1&limit=10)
GET    /api/users/{id}    - Get single user
POST   /api/users         - Create user
PUT    /api/users/{id}    - Update user
DELETE /api/users/{id}    - Delete user

Auth: Bearer token (header: Authorization)
Base URL: https://staging.ecommerce.com/api

User Object:
{
  "id": number,
  "name": string (required, 2-100 chars),
  "email": string (required, unique, valid format),
  "role": string (admin|editor|viewer)
}
```

### Tasks

1. **Generate API test file** using AI with RICE POT prompt
2. **Cover all endpoints** with at least 2 tests each:
   - Success case
   - Error case (validation, auth, not found)
3. **Use pytest fixtures** for auth token and test data
4. **Add parametrized tests** for validation scenarios
5. **Include cleanup** — delete test users after tests run
6. **Run the tests** (against a mock or real staging)

### Deliverables

- [ ] Complete `test_users_api.py` file (minimum 12 test functions)
- [ ] `conftest.py` with auth and cleanup fixtures
- [ ] Test coverage: all 5 endpoints covered
- [ ] Parametrized validation tests
- [ ] Notes on AI prompt strategy used

---

## Exercise 5: Full CI/CD Ready Test Suite

**Difficulty:** Advanced
**Time:** 60 minutes
**Tool:** All tools (Claude Code + VS Code + AI)

### Scenario

Build a CI/CD-ready test suite that combines everything learned in Chapter 4.

### Tasks

1. **Create project** with Claude Code (setup phase)
2. **Use Augment** to generate Page Objects (style matching)
3. **Use Claude Code** to generate tests (end-to-end)
4. **Add to the test file:**
   - Smoke test marker (`@pytest.mark.smoke`)
   - Regression test marker (`@pytest.mark.regression`)
   - Flaky test retry marker (`@pytest.mark.flaky(reruns=3)`)
5. **Create pytest.ini** with markers and configuration
6. **Create a run script** that executes smoke tests in CI

```bash
# run_smoke.sh
pytest -m smoke -v --html=reports/smoke_report.html
```

7. **Generate a test metrics report** for the suite

### Deliverables

- [ ] Complete project with 10+ tests
- [ ] Proper test markers (smoke, regression)
- [ ] pytest.ini configuration
- [ ] Run script for CI
- [ ] Test metrics summary

---

## Reflection Questions

1. How does AI-generated Playwright code compare to hand-written code in quality?
2. What's the most effective way to use Claude Code vs. Augment vs. Copilot for different tasks?
3. How do you ensure AI-generated selectors work against real applications?
4. What verification steps do you add after AI generates test code?

---

## Check Solutions

→ [All Exercises Solutions](ch_04_exercises_solutions.md)
